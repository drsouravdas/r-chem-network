\documentclass[]{book}

\usepackage{listings}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[]{natbib}
\bibliographystyle%
  {wileynum}%for numerical citation and numerically listed entries in the bibliography
  %{wileyauy}%for author--year citation and alphabetical order in the bibliography
\usepackage{wileySTM}
\usepackage[\ifnum\pdfoutput=1breaklinks\fi]{hyperref}

\title{Exploring the Role of Small Molecules in Biological Systems Using Network Approaches}
\author{Sourav Das and Rajarshi Guha}

% \author{Sourav Das$^\dagger$ and Rajarshi Guha$^\ddagger$}\\
% $^\dagger$St. Jude Children's Research Hospital \\ 262 Danny Thomas Place, Memphis, TN 38105 \\
% $^\ddagger$National Center for Advancing Translational Science \\ 9800 Medical Center Drive  Rockville, MD 20850}


\DeclareGraphicsExtensions{.pdf,.png}

\newcommand{\rcdk}{\texttt{rcdk}\ }
\newcommand{\igraph}{\texttt{igraph}\ }

\begin{document}
\frontmatter
\mainmatter

\chapter{Exploring the Role of Small Molecules in Biological Systems Using Network Approaches}

\section{The Role of Networks in Drug Discovery}  
\label{sec:role-networks-drug}
Omics technologies are enabling us today to elucidate and interrogate complex relationships between disease, proteins, genetic material and small molecules at an unprecedented speed and scale. Interrogation of relationships reveal common mechanism of action. This may lead to a therapeutic candidate finding application in a seemingly unrelated disease (repositioning) that share a previously unknown causal mechanism. It also allows identification of drug pairs that show synergistic activity stemming from their interactions with complementary pathways. This type of relationship elucidation may also prevent unwanted side-effects if interrogation would reveal an unexpected link to a vital pathway that ought to remain unperturbed. The process of interrogation starts with experiments aimed at elucidating molecular mechanisms and pathways such as yeast two-hybrid techniques, protein and small molecule mass spectrometry, microarray and copy number variation studies. Experiments may also include high throughput screening of millions of chemical compounds against specific biological targets of therapeutic interest to find respective agonists and antagonists. These experiments result in pairwise interaction relationships from which the functional big picture biological network can then be elucidated \cite{Wu2010}. Algorithms that detect communities from complex networks eg. community structure algorithm \cite{girvan2002community} may be used. These network analyses algorithms allow discovery of a set of sparsely interconnected subsets of vertices where the subsets themselves are however densely connected within. In the biological context, this allows connecting a set of biological cycles and smaller pathways into a big picture biological metacommunity network from which inferences on cross-reactivity and new application areas of a drug candidate can be drawn.

Network based approach to mechanism elucidation of small molecules that allow identification of synergistic pairs have been implemented in tools such as the DrugComboRanker \cite{huang2014drugcomboranker}. The authors use a community based partitioning to create a drug metacommunity network and a disease signaling metacommunity network. Drug targets are then mapped onto disease networks to allow identification of synergistic pairs of drugs and complementary mechanisms of action.
In the tool MANTRA (Mode of Action by NeTwoRk Analysis)\cite{iorio2010discovery}, authors are able to deduce mechanisms of action of new molecules and suggest repositioning of a well known molecule to a new area of application.

Network analysis has also found its application in Medicinal Chemistry and High-throughput Screening. Cheminformatics based chemical scaffold and topology networks capture the structure-activity relationships between compounds in screening experiments \cite{varin2011mining}. These help in medicinal chemistry efforts towards the identification and optimization of lead compounds for the  biological target of interest by allowing visualization of the chemical space in the backdrop of biological activity. 
  

\section{Linking Small Molecules to Targets, Pathways and Diseases}
\label{sec:link-small-molec}

Since small molecules are fundamentally weighted networks (of atoms
and bonds), a variety of graph algorithms can be applied to them to
derive invariants (also known as topological descriptors
\cite{Guha:2012vn}). However, small molecules interact with protein
targets and the targets themselves interact with each other. Such
explicit interactions lend themselves naturally to network
representations. More generally, observed or computed relationships
between small molecules, protein or gene targets and diseases allow
one to develop network representations which can then be visualized
and quantified to support integrative analyses of multiple data
types. In the following subsections we highlight applications of this
approach and where possible provide examples of R code to generate and
analyze such networks.

\subsection{Drug-target networks}
\label{sec:drug-target-networks}


\subsection{Disease networks}
\label{sec:disease-networks}

\subsection{SAR networks}
\label{sec:sar-networks}

Network representations have been used to characterize
structure-activity relationship (SAR) datasets, most notably in the
context of activity cliffs \cite{Maggiora:2006aa} - compounds that are
structurally similar, but show very different activities. In the approach
described by Guha and Van Drie \cite{Guha:2008aa}, a Structure
Activity Landscape Index (SALI) value is computed for each pair of
molecules in a dataset. The resultant matrix of SALI values is then
visualized in a network form, where compounds (nodes) are connected by
an edge if their SALI value lies above a user specified threshold
(larger SALI values imply a bigger activity cliff). An example of such
a network is shown in Figure \ref{fig:salinet}. The representation
allows one to rapidly zoom in on compound pairs that exhibit activity
cliffs. In addition, the network representation was also employed as a
way to quantify the ability of a predictive model to correctly predict
activity cliffs \cite{Guha:2008ab}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{img/salinet} 
  \caption{A SALI network constructed from XXX. See Ref.~\cite{Guha:2008aa} for further details.}
  \label{fig:salinet}
\end{figure}

Network similarity graphs (NSG's) are an alternative network
visualization of SAR data described by Wawer et al \cite{Wawer:2008aa}
that employs a different characterization of activity cliffs. This
approach is designed to multiplex information by combining
connectivity (representing similarity relationships) with node color
(potency) and size (discontinuity score \cite{Peltason:2007aa}). This
approach has been implemented in the SARANEA tool
\cite{Lounkine:2010fk} and extended \cite{Iyer:2011ij} the NSG concept
to include mechanism of action information.

Networks have been applied to a number of other SAR related
problems. For example, Webb et al \cite{Webb:2014tp} proposed a
network approach to the interpretation of arbitrary machine learning
models. Hanser et al \cite{Hanser:2014gl} constructed a network model
to represent SAR knowledge data, resulting in a ``hypothesis
network''. A key feature of this approach is the ability to integrate
disparate data types and build predictive models on top of the
network. Krein and Sukumar \cite{Krein:2011tt} describe an analysis of
chemical spaces using a graph representation and compare chemical
spaces using network metrics.

\subsection{Assay networks}
\label{sec:assay-networks}

Most high throughput screening campaigns tend to involve multiple
assays. These usually include a primary screen followed by one or more
secondary screens as well as counter-screens. When data from such
campaigns are deposited into public databases such as Pubchem, the
temporal sequence of the assays is not always maintained. As a result
it can be difficult to track the progression of chemical matter
through the series of assays. In addition, a view of the complete
assay sequence can allow one to detect commonalities between programs
and better compare the performance of screening workflows. Calhoun et
al \cite{Calhoun:2012uq} describe an approach to reconstructing
screening workflows (also termed workflow graphs) from screening
datasets. They employed four heuristic rules to construct graphs from
the data as well as using Pubchem Bioassay meta data and text mining
to identify assays from a given project. These assay networks can be
visualized using an online tool located at
\href{http://swami.wustl.edu/flow}{http://swami.wustl.edu/flow}.
Swamidass et al \cite{Swamidass:2014vn} describe an approach to
constructing ``assay networks'' based on Pubchem data, where assays
are connected when they exhibit common active (non-promiscuous)
compounds. In this approach connected assays are correlated since they
exhibit compounds with similar activities. This method leads to
connections between apparently unrelated screen allowing one to
identify compounds that exhibit polypharmacological behavior (i.e.,
activity against multiple targets) and thus are candidates for
repurposing. By also labeling screens as phenotypic or biochemical,
this approach allows one to propose target candidates based on
connectivity, thus serving as one approach to target deconvolution.

\subsection{Scaffold networks}
\label{sec:scaffold-networks}

The notion of a scaffold is common place in medicinal chemistry and is
usually considered to be a ring-containing substructure pruned of
sidechains that represents the core structure of a series of
molecules. An example is the tricyclic core common to a number of
antidepressants (e.g., amitriptylene and imipramine) shown in Figure
\ref{fig:tca-core}. Scaffolds allow one to summarize a collection of
molecules (such as in patent claims) and one can usually assume that
compounds with the same scaffold will share a common synthetic pathway
or even a common mechanism of action.
\begin{figure}[h]
  \centering
  \includegraphics{img/tca-core}
  \caption{An example of a scaffold. In this case, this
  scaffold is common to many tricyclic antidepressants.}
  \label{fig:tca-core}
\end{figure}


While a number of approaches have been described to generate scaffolds
\cite{Lewell:1998aa,Bemis:1996aa,Katritzky:2000wf}, a few approaches
have considered hierarchical decomposition of scaffolds. Examples
include the HierS method \cite{Wilkens:2005il} and the Scaffold Tree
method \cite{Schuffenhauer:2007oz}. The latter generates a series of
scaffolds based on an iterative removal of rings. The output of this
method is a series of scaffolds arranged in a tree-like structure
whose root node represents the simplest ring obtainable from the
starting scaffold.  Two scaffolds are connected if there exists a
parent--child relationship between the two. Scaffold trees generated
by this method lend themselves naturally to network
visualizations. Scaffold Hunter \cite{Wetzel:2009uq} is an example of
a tool that employs a network representation of scaffold trees. Figure
\ref{fig:scafftree} shows an example of a scaffold tree generated from
a set of 602 pyruvate kinase inhibitors. The graph is colored based on
$\log AC_{50}$ and the data is obtained from Pubchem AID 361. This
visualization lends itself naturally to adding overlays such as
molecular properties either on leaf nodes or else as aggregated values
on non-leaf nodes. The scaffold tree has been applied in a number of
studies \cite{Wetzel:2009uq,Renner:2009wm} and the structure of the
tree can be used as a guide to exploring chemical space, focusing on
regions (as represented by a scaffold) where there is minimal activity
(a ``biological hole'') or high activity.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{img/scafftree-full}
  \caption{An example of a scaffold tree displayed as a  radial
    network, generated from a set of pyruvate kinase inhibitors.}
  \label{fig:scafftree}
\end{figure}

Varin et al \cite{Varin:2011ve} describe ``scaffold networks'' which
are similar in nature to scaffold trees but instead of a tree
structure where each scaffold has a single parent, a DAG is
constructed by considering all scaffolds at a given level of the
hierarchy. An example of a scaffold network generated from Alosetron
is shown in Figure \ref{fig:scaffnet}, where the blue structures are
those that would be generated using the Scaffold Tree algorithm and
the green structures would be the extra scaffolds generated using the
Scaffold Network algorithm. Using this approach, together with the
compound set enrichment method \cite{Varin:2010zh} the authors were
able to efficiently identify active scaffold and active molecules

\begin{figure}[h]
  \centering
  \includegraphics[width=0.75\linewidth]{img/scaffold-network}
  \caption{An example of the scaffolds generated using
  the Scaffold Tree and Scaffold Network algorithms, starting from
  Alosetron. Blue scaffolds are generated by both methods and green
  scaffolds are generated only by the Scaffold Network
  method. Modified from Figure 1 in Varin et al \cite{Varin:2011ve}.}
  \label{fig:scaffnet}
\end{figure}

\subsection{Dynamic networks}
\label{sec:dynamic-networks}


\section{R as a Platform for Network Analyses in Drug Discovery}
\label{sec:r-as-platform}

The core concepts involved in computational drug discovery can be
reduced to genes, proteins, pathways and small molecules interacting
with them. Computational representations of these concepts and the
methods to be manipulate them have been implemented in a variety of
software tools. A comprehensive computational drug discovery platform
will include a number of these tools, as it is rare that a single tool
addresses all aspects.

In this sense, the R environment presents a robust platform for
computational drug discovery, especially the stages up to and
including lead optimization. The Bioconductor set of packages provide
a plethora of tools to analyze a variety of ``omics'' data. Examples
include packages that support gene expression (microarray or RNAseq)
analyses, tools for differential expression analysis, gene and pathway
enrichment analysis and so on. 

In contrast, support for small molecule data is limited. Currently,
there are two packages that focus on representing and manipulating
chemical structures - \texttt{ChemmineR} \cite{Cao:2008fj} and \rcdk
\cite{Guha:2007aa}. Both expose cheminformatics functionality
implemented in an underlying Java library (JOELib for ChemmineR and
the CDK for \rcdk). In this section we focus on the use of \rcdk as a
means to manipulate and analyze chemical structure data.

The \rcdk package supports a variety of chemical structure file
formats and presents the CDK Java API as a set of idiomatic R
functions. That is, rather than manually specify fully qualified Java
packages or resort to writing ``Java in R'' the \rcdk package wraps
much of the CDK API as ordinary R functions. Thus the atoms in a
molecule are represented as a set of atom objects. Importantly, atoms
(and other objects such as bonds and molecules) are stored as
references to Java objects. While they can be manipulated directly, it
is unwieldy it is recommended that one uses methods provided by the
\rcdk package.

For a detailed review of \rcdk functionality, the reader is referred
to Guha \cite{Guha:2007aa}. For now we focus on simple network
analyses that involve chemical structures. Given a set of compounds
represented as SMILES strings, \rcdk can be used to parse them,
compute binary fingerprints and then compute a pairwise Tanimoto
similarity matrix, as shown below
\begin{lstlisting}
library(rcdk)
library(fingerprint)

mols <- parse.smiles(mipe$SMILES_STD)
fps <- lapply(mols, get.fingerprint, type='extended')
fpsim <- fp.sim.matrix(fps)
colnames(fpsim) <- mipe$SAMPLE_NAME
rownames(fpsim) <- mipe$SAMPLE_NAME
fpsim[ fpsim < 0.6 ] <- 0
\end{lstlisting}
In this code snippet, we compute a pairwise similarity matrix that we
will eventually use as an adjacency matrix to construct the similarity
network. We only keep those similarity values greater than 0.6 so as
to focus only on similar molecules. 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.75\linewidth]{img/sim-network-connected}
  \caption{An example of a similarity network, where nodes are
    molecules and are connected if they exhibit a Tanimoto similarity
    greater than 0.6. Nodes are colored based on the PANTHER
    \cite{Mi:2005qq} class of their primary target.}
  \label{fig:simnet}
\end{figure}

The resultant similarity matrix can be treated as an adjacency matrix
and used as input to \igraph and subsequently plotted
\begin{lstlisting}
g <- graph.adjacency(fpsim, mode='undirected', 
                     weight=TRUE, diag=FALSE)
plot(g, layout=layout.fruchterman.reingold)
\end{lstlisting}
As example of such an analysis is shown in Figure \ref{fig:simnet}. In
this network, we consider a set of 1,341 compounds annotated with a
primary gene target. For each target, the highest level PANTHER
\cite{Mi:2005qq} classification was determined and used to color the
nodes. In addition, we ignore compounds that were less than 0.6
similar to any other compound (i.e., singleton nodes).

This is purely a visualization of a similarity matrix,
modified to focus on similar (according to a specified threshold)
compounds. Importantly, we have been to overlay a second type of
information (i.e., target class) on top of the similarity values and
is thus an example of the integrative nature of a network
representation.

Given the compound network and the associated target information, one
could easily identify protein-protein interactions (BioGRID
\cite{Chatr-Aryamontri:2015yf}, STRING \cite{Franceschini:2013qa} and
other sources) and generate a bipartite graph of compounds and protein
targets. Even in the trivial, annotated network show in Figure
\ref{fig:simnet} it is evident that chemical similarity is related to
functional similarity of the compounds' primary target - compounds
targeting cytoskeletal proteins tend to be similar to each other;
though interestingly, within the set of compounds targeting
cytoskeletal proteins there appear to be five distinct groupings. When
coupled to an interactive platform, this visualization can support
rapid identification and exploration of novel associations.

\section{Discussion}
\label{sec:summary}

In this chapter we have attempted to provide an overview of how
networks have been employed to analyze and visualize chemical
data. The fact that chemical structures themselves are graphs allows
one to apply a number of techniques from graph theory to characterize
chemical structure (such as the many graph invariants). However, with
the advent of large collections of chemical structures (from databases
such as Pubchem or high throughput screening programs) along with
associated data such as bioactivity and target annotations, a number
of workers have attempted to analyze the properties of such
collections using network techniques.

It is interesting to note that many applications of network methods to
chemical collections focus on visualization of the chemical data,
rather than using the network structure to draw insight into the
underlying chemical of biological phenomena. This is not to say that
network visualizations of chemical data are lacking. In fact, such
visualizations allow one to encode multiple properties of objects
(i.e., nodes) and relationships (i.e., edges) in a single visual form. 

However, a key utility of network approaches is the ability to
integrate different data types (such as small molecules and their
protein targets) in to a single data structure. Drug-target or
drug-disease (or even drug-disease-target) networks are examples of
such approaches. Hartsperger et al \cite{Hartsperger:2010yg} describe
an approach to fuzzy clustering that is capable of identifying
subgraphs with heterogenous networks. A characteristic feature of such
$k$-partite networks is that it allows one to model the effects of
each class of entity on other classes of entities. This is exemplified
by random walk approaches on bipartite networks such as that described
by Chen et al \cite{Chen:2012qy} whose proposed a random walk approach
to predict drug-target interactions.

\bibliography{paper}

\end{document}
